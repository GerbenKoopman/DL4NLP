{
  "best_global_step": 68,
  "best_metric": 1.1039135456085205,
  "best_model_checkpoint": "results/lora_base_to_target_1b_5e/lora_1b/checkpoint-68",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 68,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 154.16860961914062,
      "learning_rate": 0.0002,
      "loss": 13.7721,
      "step": 1
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 163.0421600341797,
      "learning_rate": 0.00019764705882352942,
      "loss": 12.1747,
      "step": 2
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 289.4847106933594,
      "learning_rate": 0.00019529411764705883,
      "loss": 9.4599,
      "step": 3
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 275.8097839355469,
      "learning_rate": 0.00019294117647058825,
      "loss": 8.0274,
      "step": 4
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 267.3674621582031,
      "learning_rate": 0.00019058823529411766,
      "loss": 7.1512,
      "step": 5
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 314.45635986328125,
      "learning_rate": 0.00018823529411764707,
      "loss": 6.8075,
      "step": 6
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 25.348011016845703,
      "learning_rate": 0.00018588235294117648,
      "loss": 6.6489,
      "step": 7
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 33.933204650878906,
      "learning_rate": 0.0001835294117647059,
      "loss": 5.9284,
      "step": 8
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 58.446041107177734,
      "learning_rate": 0.0001811764705882353,
      "loss": 5.9534,
      "step": 9
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 45.915916442871094,
      "learning_rate": 0.00017882352941176472,
      "loss": 5.3182,
      "step": 10
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 62.394630432128906,
      "learning_rate": 0.00017647058823529413,
      "loss": 4.8927,
      "step": 11
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 42.064640045166016,
      "learning_rate": 0.00017411764705882354,
      "loss": 4.0649,
      "step": 12
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 30.493738174438477,
      "learning_rate": 0.00017176470588235293,
      "loss": 3.4465,
      "step": 13
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 27.36778450012207,
      "learning_rate": 0.00016941176470588237,
      "loss": 2.8806,
      "step": 14
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 27.44339370727539,
      "learning_rate": 0.00016705882352941178,
      "loss": 2.2605,
      "step": 15
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 17511626.0,
      "learning_rate": 0.0001647058823529412,
      "loss": 1.757,
      "step": 16
    },
    {
      "epoch": 1.0,
      "grad_norm": 95.72850036621094,
      "learning_rate": 0.0001623529411764706,
      "loss": 1.6545,
      "step": 17
    },
    {
      "epoch": 1.0,
      "eval_bleu": 5.097693854507489,
      "eval_chrf": 36.217389067189934,
      "eval_loss": 2.0481622219085693,
      "eval_runtime": 35.2313,
      "eval_samples_per_second": 0.284,
      "eval_steps_per_second": 0.142,
      "step": 17
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 67.92671966552734,
      "learning_rate": 0.00016,
      "loss": 1.5136,
      "step": 18
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 14.984734535217285,
      "learning_rate": 0.00015764705882352943,
      "loss": 1.4548,
      "step": 19
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 6.36760950088501,
      "learning_rate": 0.00015529411764705884,
      "loss": 1.6613,
      "step": 20
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 4.1535210609436035,
      "learning_rate": 0.00015294117647058822,
      "loss": 1.4108,
      "step": 21
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 2.205568313598633,
      "learning_rate": 0.00015058823529411766,
      "loss": 1.277,
      "step": 22
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 2.6780104637145996,
      "learning_rate": 0.00014823529411764707,
      "loss": 1.2652,
      "step": 23
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 13.114219665527344,
      "learning_rate": 0.00014588235294117646,
      "loss": 1.3363,
      "step": 24
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 12.19729232788086,
      "learning_rate": 0.0001435294117647059,
      "loss": 1.3479,
      "step": 25
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 2.3885726928710938,
      "learning_rate": 0.0001411764705882353,
      "loss": 1.277,
      "step": 26
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 2.729912281036377,
      "learning_rate": 0.00013882352941176472,
      "loss": 1.3469,
      "step": 27
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 2.181459426879883,
      "learning_rate": 0.00013647058823529413,
      "loss": 1.1204,
      "step": 28
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 2.0155863761901855,
      "learning_rate": 0.00013411764705882352,
      "loss": 1.1685,
      "step": 29
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 2.978508234024048,
      "learning_rate": 0.00013176470588235296,
      "loss": 1.0554,
      "step": 30
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 3.811596393585205,
      "learning_rate": 0.00012941176470588237,
      "loss": 0.9405,
      "step": 31
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 4.355658531188965,
      "learning_rate": 0.00012705882352941175,
      "loss": 0.9636,
      "step": 32
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 2.5627353191375732,
      "learning_rate": 0.0001247058823529412,
      "loss": 0.8388,
      "step": 33
    },
    {
      "epoch": 2.0,
      "grad_norm": 13.2246675491333,
      "learning_rate": 0.0001223529411764706,
      "loss": 1.091,
      "step": 34
    },
    {
      "epoch": 2.0,
      "eval_bleu": 21.785893406435186,
      "eval_chrf": 47.87220417072866,
      "eval_loss": 1.312011480331421,
      "eval_runtime": 48.6195,
      "eval_samples_per_second": 0.206,
      "eval_steps_per_second": 0.103,
      "step": 34
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 3.0210835933685303,
      "learning_rate": 0.00012,
      "loss": 0.8707,
      "step": 35
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 7.926208019256592,
      "learning_rate": 0.00011764705882352942,
      "loss": 0.894,
      "step": 36
    },
    {
      "epoch": 2.176470588235294,
      "grad_norm": 4.713943958282471,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.9196,
      "step": 37
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 3.595421314239502,
      "learning_rate": 0.00011294117647058824,
      "loss": 0.9569,
      "step": 38
    },
    {
      "epoch": 2.2941176470588234,
      "grad_norm": 8.204973220825195,
      "learning_rate": 0.00011058823529411766,
      "loss": 0.8715,
      "step": 39
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 38.881893157958984,
      "learning_rate": 0.00010823529411764706,
      "loss": 0.9606,
      "step": 40
    },
    {
      "epoch": 2.411764705882353,
      "grad_norm": 18.993778228759766,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.7232,
      "step": 41
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 11.380624771118164,
      "learning_rate": 0.0001035294117647059,
      "loss": 0.893,
      "step": 42
    },
    {
      "epoch": 2.5294117647058822,
      "grad_norm": 4.90207576751709,
      "learning_rate": 0.0001011764705882353,
      "loss": 0.8514,
      "step": 43
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 58.082210540771484,
      "learning_rate": 9.882352941176471e-05,
      "loss": 0.8986,
      "step": 44
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 29.77227020263672,
      "learning_rate": 9.647058823529412e-05,
      "loss": 0.8796,
      "step": 45
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 5.734318256378174,
      "learning_rate": 9.411764705882353e-05,
      "loss": 0.8907,
      "step": 46
    },
    {
      "epoch": 2.764705882352941,
      "grad_norm": 3.6419193744659424,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.6926,
      "step": 47
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 3.426522731781006,
      "learning_rate": 8.941176470588236e-05,
      "loss": 0.7117,
      "step": 48
    },
    {
      "epoch": 2.8823529411764706,
      "grad_norm": 53.40394973754883,
      "learning_rate": 8.705882352941177e-05,
      "loss": 0.9946,
      "step": 49
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 20.914268493652344,
      "learning_rate": 8.470588235294118e-05,
      "loss": 0.8993,
      "step": 50
    },
    {
      "epoch": 3.0,
      "grad_norm": 14.207995414733887,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.8141,
      "step": 51
    },
    {
      "epoch": 3.0,
      "eval_bleu": 38.08414034109084,
      "eval_chrf": 55.47705241876003,
      "eval_loss": 1.1575250625610352,
      "eval_runtime": 43.2145,
      "eval_samples_per_second": 0.231,
      "eval_steps_per_second": 0.116,
      "step": 51
    },
    {
      "epoch": 3.0588235294117645,
      "grad_norm": 3.047544479370117,
      "learning_rate": 8e-05,
      "loss": 0.6828,
      "step": 52
    },
    {
      "epoch": 3.1176470588235294,
      "grad_norm": 2.8687143325805664,
      "learning_rate": 7.764705882352942e-05,
      "loss": 0.9772,
      "step": 53
    },
    {
      "epoch": 3.176470588235294,
      "grad_norm": 1.226879596710205,
      "learning_rate": 7.529411764705883e-05,
      "loss": 0.8149,
      "step": 54
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 34.47321319580078,
      "learning_rate": 7.294117647058823e-05,
      "loss": 0.8605,
      "step": 55
    },
    {
      "epoch": 3.2941176470588234,
      "grad_norm": 26.61481475830078,
      "learning_rate": 7.058823529411765e-05,
      "loss": 0.7769,
      "step": 56
    },
    {
      "epoch": 3.3529411764705883,
      "grad_norm": 6.43243408203125,
      "learning_rate": 6.823529411764707e-05,
      "loss": 0.8393,
      "step": 57
    },
    {
      "epoch": 3.411764705882353,
      "grad_norm": 2.503835678100586,
      "learning_rate": 6.588235294117648e-05,
      "loss": 0.7425,
      "step": 58
    },
    {
      "epoch": 3.4705882352941178,
      "grad_norm": 2.4536590576171875,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.8141,
      "step": 59
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 2.7444639205932617,
      "learning_rate": 6.11764705882353e-05,
      "loss": 0.986,
      "step": 60
    },
    {
      "epoch": 3.588235294117647,
      "grad_norm": 3.4977569580078125,
      "learning_rate": 5.882352941176471e-05,
      "loss": 0.7081,
      "step": 61
    },
    {
      "epoch": 3.6470588235294117,
      "grad_norm": 12.133088111877441,
      "learning_rate": 5.647058823529412e-05,
      "loss": 0.7916,
      "step": 62
    },
    {
      "epoch": 3.7058823529411766,
      "grad_norm": 29.50202178955078,
      "learning_rate": 5.411764705882353e-05,
      "loss": 0.6073,
      "step": 63
    },
    {
      "epoch": 3.764705882352941,
      "grad_norm": 6.130547523498535,
      "learning_rate": 5.176470588235295e-05,
      "loss": 0.7059,
      "step": 64
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 3.811697006225586,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 0.7981,
      "step": 65
    },
    {
      "epoch": 3.8823529411764706,
      "grad_norm": 1.0404081344604492,
      "learning_rate": 4.705882352941177e-05,
      "loss": 0.6555,
      "step": 66
    },
    {
      "epoch": 3.9411764705882355,
      "grad_norm": 1.4878828525543213,
      "learning_rate": 4.470588235294118e-05,
      "loss": 0.6815,
      "step": 67
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.8367738723754883,
      "learning_rate": 4.235294117647059e-05,
      "loss": 0.7306,
      "step": 68
    },
    {
      "epoch": 4.0,
      "eval_bleu": 37.60569333033305,
      "eval_chrf": 55.53507405949365,
      "eval_loss": 1.1039135456085205,
      "eval_runtime": 39.0177,
      "eval_samples_per_second": 0.256,
      "eval_steps_per_second": 0.128,
      "step": 68
    }
  ],
  "logging_steps": 1,
  "max_steps": 85,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 861582340915200.0,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}
