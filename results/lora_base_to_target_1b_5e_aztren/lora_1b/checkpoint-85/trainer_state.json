{
  "best_global_step": 85,
  "best_metric": 1.061476469039917,
  "best_model_checkpoint": "results/lora_base_to_target_1b_5e_aztren/lora_1b/checkpoint-85",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 85,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 176.50311279296875,
      "learning_rate": 0.0002,
      "loss": 13.7721,
      "step": 1
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 179.8058319091797,
      "learning_rate": 0.00019764705882352942,
      "loss": 12.1054,
      "step": 2
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 303.2118835449219,
      "learning_rate": 0.00019529411764705883,
      "loss": 9.3902,
      "step": 3
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 268.8289489746094,
      "learning_rate": 0.00019294117647058825,
      "loss": 7.9956,
      "step": 4
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 241.202392578125,
      "learning_rate": 0.00019058823529411766,
      "loss": 7.1377,
      "step": 5
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 258.74664306640625,
      "learning_rate": 0.00018823529411764707,
      "loss": 6.7894,
      "step": 6
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 27.421863555908203,
      "learning_rate": 0.00018588235294117648,
      "loss": 6.616,
      "step": 7
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 30.608274459838867,
      "learning_rate": 0.0001835294117647059,
      "loss": 5.8734,
      "step": 8
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 49.04313278198242,
      "learning_rate": 0.0001811764705882353,
      "loss": 5.8305,
      "step": 9
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 56.4614372253418,
      "learning_rate": 0.00017882352941176472,
      "loss": 5.1419,
      "step": 10
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 64.22350311279297,
      "learning_rate": 0.00017647058823529413,
      "loss": 4.6001,
      "step": 11
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 37.68014907836914,
      "learning_rate": 0.00017411764705882354,
      "loss": 3.7954,
      "step": 12
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 26.62456703186035,
      "learning_rate": 0.00017176470588235293,
      "loss": 3.1518,
      "step": 13
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 29.00422477722168,
      "learning_rate": 0.00016941176470588237,
      "loss": 2.6438,
      "step": 14
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 25.005939483642578,
      "learning_rate": 0.00016705882352941178,
      "loss": 2.0806,
      "step": 15
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 12.316771507263184,
      "learning_rate": 0.0001647058823529412,
      "loss": 1.672,
      "step": 16
    },
    {
      "epoch": 1.0,
      "grad_norm": 22.9793643951416,
      "learning_rate": 0.0001623529411764706,
      "loss": 1.2509,
      "step": 17
    },
    {
      "epoch": 1.0,
      "eval_bleu": 5.097693854507489,
      "eval_chrf": 36.01038578453324,
      "eval_loss": 1.959214448928833,
      "eval_runtime": 33.4334,
      "eval_samples_per_second": 0.299,
      "eval_steps_per_second": 0.15,
      "step": 17
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 5.648497581481934,
      "learning_rate": 0.00016,
      "loss": 1.215,
      "step": 18
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 3.4274425506591797,
      "learning_rate": 0.00015764705882352943,
      "loss": 1.3076,
      "step": 19
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 4.261873722076416,
      "learning_rate": 0.00015529411764705884,
      "loss": 1.54,
      "step": 20
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 7.1155829429626465,
      "learning_rate": 0.00015294117647058822,
      "loss": 1.2949,
      "step": 21
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 9.078493118286133,
      "learning_rate": 0.00015058823529411766,
      "loss": 1.1827,
      "step": 22
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 2.751727342605591,
      "learning_rate": 0.00014823529411764707,
      "loss": 1.1788,
      "step": 23
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 4.1806440353393555,
      "learning_rate": 0.00014588235294117646,
      "loss": 1.2456,
      "step": 24
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 4.56257438659668,
      "learning_rate": 0.0001435294117647059,
      "loss": 1.2599,
      "step": 25
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 2.432111978530884,
      "learning_rate": 0.0001411764705882353,
      "loss": 1.1889,
      "step": 26
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 7.772373676300049,
      "learning_rate": 0.00013882352941176472,
      "loss": 1.2547,
      "step": 27
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 7.640100479125977,
      "learning_rate": 0.00013647058823529413,
      "loss": 1.0468,
      "step": 28
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 42.336116790771484,
      "learning_rate": 0.00013411764705882352,
      "loss": 1.1761,
      "step": 29
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 4.11871862411499,
      "learning_rate": 0.00013176470588235296,
      "loss": 1.0039,
      "step": 30
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 4.4177327156066895,
      "learning_rate": 0.00012941176470588237,
      "loss": 0.9143,
      "step": 31
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 3.3018240928649902,
      "learning_rate": 0.00012705882352941175,
      "loss": 0.9446,
      "step": 32
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 2.219320774078369,
      "learning_rate": 0.0001247058823529412,
      "loss": 0.8244,
      "step": 33
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.817643404006958,
      "learning_rate": 0.0001223529411764706,
      "loss": 1.062,
      "step": 34
    },
    {
      "epoch": 2.0,
      "eval_bleu": 22.6366574007087,
      "eval_chrf": 48.21555557335521,
      "eval_loss": 1.2805635929107666,
      "eval_runtime": 36.3739,
      "eval_samples_per_second": 0.275,
      "eval_steps_per_second": 0.137,
      "step": 34
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 14.198436737060547,
      "learning_rate": 0.00012,
      "loss": 0.8753,
      "step": 35
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 7.026272773742676,
      "learning_rate": 0.00011764705882352942,
      "loss": 0.8841,
      "step": 36
    },
    {
      "epoch": 2.176470588235294,
      "grad_norm": 1.8988590240478516,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.9027,
      "step": 37
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 2.337533950805664,
      "learning_rate": 0.00011294117647058824,
      "loss": 0.9466,
      "step": 38
    },
    {
      "epoch": 2.2941176470588234,
      "grad_norm": 2.162515163421631,
      "learning_rate": 0.00011058823529411766,
      "loss": 0.8538,
      "step": 39
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 7.716549396514893,
      "learning_rate": 0.00010823529411764706,
      "loss": 0.899,
      "step": 40
    },
    {
      "epoch": 2.411764705882353,
      "grad_norm": 12.818595886230469,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.7013,
      "step": 41
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 14.821983337402344,
      "learning_rate": 0.0001035294117647059,
      "loss": 0.8844,
      "step": 42
    },
    {
      "epoch": 2.5294117647058822,
      "grad_norm": 2.12101149559021,
      "learning_rate": 0.0001011764705882353,
      "loss": 0.824,
      "step": 43
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 47.24660873413086,
      "learning_rate": 9.882352941176471e-05,
      "loss": 0.8231,
      "step": 44
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 3.97641658782959,
      "learning_rate": 9.647058823529412e-05,
      "loss": 0.8439,
      "step": 45
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 2.026024580001831,
      "learning_rate": 9.411764705882353e-05,
      "loss": 0.8701,
      "step": 46
    },
    {
      "epoch": 2.764705882352941,
      "grad_norm": 1.8443951606750488,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.6711,
      "step": 47
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 1.686457872390747,
      "learning_rate": 8.941176470588236e-05,
      "loss": 0.6814,
      "step": 48
    },
    {
      "epoch": 2.8823529411764706,
      "grad_norm": 57.573997497558594,
      "learning_rate": 8.705882352941177e-05,
      "loss": 0.9584,
      "step": 49
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 74.79418182373047,
      "learning_rate": 8.470588235294118e-05,
      "loss": 1.0291,
      "step": 50
    },
    {
      "epoch": 3.0,
      "grad_norm": 134.8126220703125,
      "learning_rate": 8.23529411764706e-05,
      "loss": 1.2048,
      "step": 51
    },
    {
      "epoch": 3.0,
      "eval_bleu": 39.4889626843945,
      "eval_chrf": 57.04519689939619,
      "eval_loss": 1.1238563060760498,
      "eval_runtime": 50.8112,
      "eval_samples_per_second": 0.197,
      "eval_steps_per_second": 0.098,
      "step": 51
    },
    {
      "epoch": 3.0588235294117645,
      "grad_norm": 44.56415939331055,
      "learning_rate": 8e-05,
      "loss": 0.7532,
      "step": 52
    },
    {
      "epoch": 3.1176470588235294,
      "grad_norm": 3.8789453506469727,
      "learning_rate": 7.764705882352942e-05,
      "loss": 0.937,
      "step": 53
    },
    {
      "epoch": 3.176470588235294,
      "grad_norm": 1.7675755023956299,
      "learning_rate": 7.529411764705883e-05,
      "loss": 0.7915,
      "step": 54
    },
    {
      "epoch": 3.235294117647059,
      "grad_norm": 1.831062912940979,
      "learning_rate": 7.294117647058823e-05,
      "loss": 0.7849,
      "step": 55
    },
    {
      "epoch": 3.2941176470588234,
      "grad_norm": 8.428122520446777,
      "learning_rate": 7.058823529411765e-05,
      "loss": 0.7195,
      "step": 56
    },
    {
      "epoch": 3.3529411764705883,
      "grad_norm": 1.8161760568618774,
      "learning_rate": 6.823529411764707e-05,
      "loss": 0.8148,
      "step": 57
    },
    {
      "epoch": 3.411764705882353,
      "grad_norm": 1.809756875038147,
      "learning_rate": 6.588235294117648e-05,
      "loss": 0.7143,
      "step": 58
    },
    {
      "epoch": 3.4705882352941178,
      "grad_norm": 1.5051997900009155,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.7775,
      "step": 59
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 6.262780666351318,
      "learning_rate": 6.11764705882353e-05,
      "loss": 0.9472,
      "step": 60
    },
    {
      "epoch": 3.588235294117647,
      "grad_norm": 11.203544616699219,
      "learning_rate": 5.882352941176471e-05,
      "loss": 0.6898,
      "step": 61
    },
    {
      "epoch": 3.6470588235294117,
      "grad_norm": 39.86927795410156,
      "learning_rate": 5.647058823529412e-05,
      "loss": 0.8313,
      "step": 62
    },
    {
      "epoch": 3.7058823529411766,
      "grad_norm": 23.668363571166992,
      "learning_rate": 5.411764705882353e-05,
      "loss": 0.6287,
      "step": 63
    },
    {
      "epoch": 3.764705882352941,
      "grad_norm": 11.546893119812012,
      "learning_rate": 5.176470588235295e-05,
      "loss": 0.6931,
      "step": 64
    },
    {
      "epoch": 3.8235294117647056,
      "grad_norm": 6.978142738342285,
      "learning_rate": 4.9411764705882355e-05,
      "loss": 0.7732,
      "step": 65
    },
    {
      "epoch": 3.8823529411764706,
      "grad_norm": 1.2504147291183472,
      "learning_rate": 4.705882352941177e-05,
      "loss": 0.6359,
      "step": 66
    },
    {
      "epoch": 3.9411764705882355,
      "grad_norm": 1.550323724746704,
      "learning_rate": 4.470588235294118e-05,
      "loss": 0.6596,
      "step": 67
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.5577116012573242,
      "learning_rate": 4.235294117647059e-05,
      "loss": 0.7058,
      "step": 68
    },
    {
      "epoch": 4.0,
      "eval_bleu": 37.45251589474739,
      "eval_chrf": 55.416935629001344,
      "eval_loss": 1.0770883560180664,
      "eval_runtime": 40.6483,
      "eval_samples_per_second": 0.246,
      "eval_steps_per_second": 0.123,
      "step": 68
    },
    {
      "epoch": 4.0588235294117645,
      "grad_norm": 1.1360020637512207,
      "learning_rate": 4e-05,
      "loss": 0.551,
      "step": 69
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 1.2824174165725708,
      "learning_rate": 3.7647058823529415e-05,
      "loss": 0.6791,
      "step": 70
    },
    {
      "epoch": 4.176470588235294,
      "grad_norm": 1.21959388256073,
      "learning_rate": 3.529411764705883e-05,
      "loss": 0.7158,
      "step": 71
    },
    {
      "epoch": 4.235294117647059,
      "grad_norm": 1.4706279039382935,
      "learning_rate": 3.294117647058824e-05,
      "loss": 0.5913,
      "step": 72
    },
    {
      "epoch": 4.294117647058823,
      "grad_norm": 3.758857011795044,
      "learning_rate": 3.058823529411765e-05,
      "loss": 0.7746,
      "step": 73
    },
    {
      "epoch": 4.352941176470588,
      "grad_norm": 1.3848780393600464,
      "learning_rate": 2.823529411764706e-05,
      "loss": 0.8758,
      "step": 74
    },
    {
      "epoch": 4.411764705882353,
      "grad_norm": 0.8114121556282043,
      "learning_rate": 2.5882352941176475e-05,
      "loss": 0.6581,
      "step": 75
    },
    {
      "epoch": 4.470588235294118,
      "grad_norm": 1.286993384361267,
      "learning_rate": 2.3529411764705884e-05,
      "loss": 0.6795,
      "step": 76
    },
    {
      "epoch": 4.529411764705882,
      "grad_norm": 0.8643888831138611,
      "learning_rate": 2.1176470588235296e-05,
      "loss": 0.6442,
      "step": 77
    },
    {
      "epoch": 4.588235294117647,
      "grad_norm": 1.9002330303192139,
      "learning_rate": 1.8823529411764708e-05,
      "loss": 0.8098,
      "step": 78
    },
    {
      "epoch": 4.647058823529412,
      "grad_norm": 0.998875617980957,
      "learning_rate": 1.647058823529412e-05,
      "loss": 0.7526,
      "step": 79
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.9647912383079529,
      "learning_rate": 1.411764705882353e-05,
      "loss": 0.6279,
      "step": 80
    },
    {
      "epoch": 4.764705882352941,
      "grad_norm": 0.9566210508346558,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 0.6556,
      "step": 81
    },
    {
      "epoch": 4.823529411764706,
      "grad_norm": 2.2640440464019775,
      "learning_rate": 9.411764705882354e-06,
      "loss": 0.7647,
      "step": 82
    },
    {
      "epoch": 4.882352941176471,
      "grad_norm": 1.6432522535324097,
      "learning_rate": 7.058823529411765e-06,
      "loss": 0.789,
      "step": 83
    },
    {
      "epoch": 4.9411764705882355,
      "grad_norm": 0.9788275361061096,
      "learning_rate": 4.705882352941177e-06,
      "loss": 0.6493,
      "step": 84
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.4195266962051392,
      "learning_rate": 2.3529411764705885e-06,
      "loss": 0.7948,
      "step": 85
    },
    {
      "epoch": 5.0,
      "eval_bleu": 39.375626296217135,
      "eval_chrf": 57.3028281128873,
      "eval_loss": 1.061476469039917,
      "eval_runtime": 44.5095,
      "eval_samples_per_second": 0.225,
      "eval_steps_per_second": 0.112,
      "step": 85
    }
  ],
  "logging_steps": 1,
  "max_steps": 85,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1076977926144000.0,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}
